{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF_IDF App\n",
    "\n",
    "#### I've build my own DF-IDF app for understanding the importance of a word within a document of a given corpus. Check it out below:\n",
    "\n",
    "#### Mike Bourne, October 2020\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---------------------------\n",
    "\n",
    "Theory\n",
    "\n",
    "The <b>inverse document frequency (IDF)</b> is a measure of how much information the word provides, i.e., if it's common or rare across all documents. It is the logarithmically scaled inverse fraction of the documents that contain the word (obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient).\n",
    "\n",
    "$ \\mathrm{idf}(t, D)$ =  $\\log \\frac{N}{|\\{d \\in D: t \\in d\\}|}$\n",
    "\n",
    "with\n",
    "\n",
    "$N$: total number of documents in the corpus $N=|D|$\n",
    "\n",
    "$\\{d \\in D: t \\in d\\} $ : number of documents where the term $t$ appears \n",
    "\n",
    "<br>\n",
    "\n",
    "The <b>total frequency (TF)</b> is the number of times a word (t) appears in a given document (d);  \n",
    "\n",
    "${tf}(t,d) $\n",
    "\n",
    "<br>\n",
    "\n",
    "Thus, The <b>TF-IDF</b> is simply a measure of the number of times a word appears in a given document, weighted by the number of documents containing that word across a corpus. It is given by:\n",
    "\n",
    "${\\displaystyle \\mathrm {tfidf} (t,d,D)=\\mathrm {tf} (t,d)\\cdot \\mathrm {idf} (t,D)}$\n",
    "\n",
    "---------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a funciton to return unique set of words in a particular input file\n",
    "def unique_words(input_file,flag):\n",
    "\n",
    "    #open file, get string of all contents, close file\n",
    "    file = open(input_file, 'r')\n",
    "    text_all = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    #split out words, remove non-alpha symbols, make all lower case\n",
    "    words = text_all.split()\n",
    "    for i in range(0,len(words)):\n",
    "        words[i] = words[i].lower().strip(',').strip('.')\n",
    "\n",
    "    #create dict of the frequency of each word\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        word_freq[word] = word_freq.get(word,0) + 1\n",
    "       \n",
    "    #return a set of unique words by using set function when flag-0\n",
    "    if(flag == 0):\n",
    "        return set(words)\n",
    "    #or return the frequency of the words in the file (as a dictionary)\n",
    "    else:\n",
    "        return word_freq\n",
    "        print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text3.txt   0.0 it\n",
      "text3.txt   0.0 has\n",
      "text3.txt   0.0 a\n",
      "text3.txt   0.0 number\n",
      "text3.txt   0.0 of\n",
      "text2.txt   5.49 bourne\n",
      "text2.txt   1.22 files\n",
      "text2.txt   1.1 3.20\n",
      "text2.txt   1.1 i\n",
      "text2.txt   1.1 comparing\n",
      "text.txt   1.1 this\n",
      "text.txt   1.1 text\n",
      "text.txt   1.1 file\n",
      "text.txt   1.1 contains\n",
      "text.txt   1.1 3.16\n"
     ]
    }
   ],
   "source": [
    "#set up a frequency count for words in a dictionary \n",
    "words_freq = {}\n",
    "\n",
    "#get list of all files in dictionary\n",
    "import os\n",
    "list_files = os.listdir()\n",
    "\n",
    "no_files = 0\n",
    "for file in list_files:\n",
    "    \n",
    "    #if file ends in '.txt' then must be a text file\n",
    "    if ( file[-4:] == '.txt' ):\n",
    "        no_files += 1\n",
    "        \n",
    "        # use function to return a list of unique words within that text file\n",
    "        file_words = unique_words(file,0)\n",
    "              \n",
    "        #go through each unique word and +1 to its occurance in the count_words dictionary\n",
    "        for word in file_words:\n",
    "            words_freq[word] = words_freq.get(word,0) + 1 \n",
    "\n",
    "#calcualte IDF \n",
    "import math\n",
    "for word in words_freq:\n",
    "    words_freq[word] = math.log(no_files/(words_freq[word]))\n",
    "\n",
    "# again loop through each file\n",
    "for file in list_files:\n",
    "    if ( file[-4:] == '.txt' ): \n",
    "        \n",
    "        # use function to return a dictionary containing freq of each word\n",
    "        word_freq = unique_words(file,1)\n",
    "\n",
    "        # calculate dictionary DF_IDF (using comprehension), sort data\n",
    "        df_idf = { word: word_freq[word]*words_freq[word] for word in word_freq}\n",
    "        sorted_df_idf = sorted(df_idf.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        #print output to screen (top 5 in each file)\n",
    "        for word in sorted_df_idf[:5]:\n",
    "            print(file, ' ' ,round(word[1],2), word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
